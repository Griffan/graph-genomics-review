\section{Building the pangenome}

A collection of genomic sequences, either raw reads or assembled genomes, can itself provide a pangenomic model.
But this model lacks a mechanism to define the relationships between the sequences.
It cannot assert anything more than the presence of a given sequence in the pangenome.
In practice, we need to know when a particular sequence is identical to another by descent from a common ancestor.
This information suggests phylogenetic structures that result from evolutionary processes, which can in turn help support our understanding of 

Furthermore, the identity of sequences by descent provides a basis for the compact representation of sequences.
Our model need not grow linearly with the number of genomes that it includes.
Rather, we should obtain improved compression of individual genomes in the context of a pangenome.
Shared segments of DNA only need to be represented once.
If most DNA is shared, then this makes the unique sequences of the pangenome much smaller than the total sequences in the genomes that we use to build it, providing compression that is both practical and helpful for analyses.

Methods to construct pangenomic data structures mirror the classes of pangenomic models.
A pangenome may simply be a collection of sequences, in which case construction is similar to the genome or metagenome assembly problem.
Or, it may include information about the alignment of sequences.
This alignment could be compressed into a set of variants found against a set of reference sequences.
If this alignment is based on $k$-mers, then it implies a de Bruijn graph, and various methods exploit this to implement efficient or scalable pangenome model construction.
If the alignments is a complete, gapped alignment, covering small and large variation, then the pangenome model can be thought of as a whole genome alignment.
Methods for pangenome construction often use a mixture of approaches, but in most cases their aim is to emulate the full all-to-all alignment of the base sequences.

%The great majority of pangenome construction methods generate or use graphical models
% new organization
% 1) bags of sequences -- pantools comes close (collection of genes), HUPAN is similar with its core/accessory breakdown
% 2) DBG based models (TwoPaCo, LOGAN, McCortex, Bifrost, PRG, Novograph?)
% 3) alignment and match based systems (cactus, REVEAL, vg msga, seqwish)

\subsection{Collecting sequences}

% oldschool pan-genomics
Panseq \cite{Laing_2010}
PGAP \cite{Zhao_2011}
% pangenome using a collection of sequences model
PanTools  \cite{Sheikhizadeh_Anari_2018}
HUPAN \citep{Duan_2019}

\subsection{Adding variation}

GenomeMapper was the first major tool to use a reference genome graph \cite{Schneeberger_2009}.
PRG \cite{dilthey2015improved}.
vg construct \cite{Garrison_2018}.

\subsection{Colored and linked De Bruijn graphs}

% dbg methods with pangenomic flavors (coloring)
Cortex \cite{Iqbal_2012}
Bifrost \cite{holley2019bifrost}

McCortex \cite{Turner_2018}
LOGAN \cite{Bolger_2017}

\subsection{Whole genome alignments}

% whole genome alignments
Multiple sequence alignments (predecessor) POA and PO-POA \cite{Lee_2002,Grasso_2004} % only small graphs

Alignment based pangenome models.

Cactus \cite{Paten_2011} as demonstrated in alignathon \cite{earl2014alignathon}
REVEAL \cite{linthorst2015scalable}
TwoPaCo \cite{Minkin_2016}
vg msga \cite{Novak_2017a,Garrison_2018,Garrison_2019}
Novograph \cite{Biederstedt2018}
Seqwish\footnote{\url{https://github.com/ekg/seqwish}} \cite{Garrison_2019}


\subsection{Graph genome coordinates}

\textit{This needs to be rewritten!! The idea is to focus on bubbles and positions at the same time.} \cite{Rand_2016}

\subsection{Measuring and improving graph utility}

Because \texttt{vg} provides an integrated toolkit for constructing, manipulating, and using genome graphs, it's a tool well-suited for comparing the efficacy of different genome graph construction techniques \cite{Novak_2017, Garrison_2018}.
In the paper ``Genome Graphs'', \citeauthor{Novak_2017a}\ compared different graph constructions based on their utility in read mapping, variant calling, and general graph character \citep{Novak_2017a} \todo{Does it really make sense to lean so heavily on our own unreviewed, unpublished manuscript in a review?}.
They found that genome graphs in general provide superior read mapping and variant calling to their linear counterparts, and that different construction approaches varied greatly even within each region of the genome.
To quantify this variability, they proposed three normalized graph metrics.
 \emph{Graph compression} is the length of primary reference sequence divided by the sum of the length of the nodes in the graph.
It essentially measures the quantity of alt path sequence represented in the graph with respect to the size of the reference.
The \emph{(base) degree} of the graph measures how much branching occurs in the graph, and the \emph{cut width} measures apparent sequence rearrangement \todo{We don't have any evidence to support these being useful or accepted metrics, though.}.

In the same study, \citeauthor{Novak_2017a}\ demonstrated that their graphs improved mapping precision when more polymorphisms were added to the graph.
As they pointed out, this is a potentially surprising result: they originally thought that adding more sequences similar to the read's target would reduce the likelihood of the read mapping to the correct region.
Instead, adding known variants helped the mapping algorithm distinguish their true mapping location from other, paralogous sequences \citep{Novak_2017a}.

Adding more variants to the graph doesn't always improve mapping precision, however.
FORGe is a tool for modeling the effects of adding a variant to the graph \cite{Pritt_2018}. 
The primary benefit of adding a variant to the graph is that it increases the graph's representation of sequence diversity.
Without variance in the graph, reads with significant sequence dissimilarity from the linear genome won't be mapped to the correct region, or won't be mapped at all.
Sometimes, however, adding a variant can reduce alignment accuracy by increasing the ambiguity of similar sequences already in the graph.
In addition, adding variants to the graph can increase the cost of storing and querying the genome index.
To predict the effects of adding a variant, FORGe scores variants based on their frequency in a population, its proximity to other variants, and how it increases/decreases repetitive sequence in the genome.
It can then output a list of top-scoring variants for use in a graph aligner.
\todo{How do we square the results showing FORGe is needed with the results from our unpublished Graph Genomes manuscript? We don't do that work here.}


\section{Indexing pangenomes} % was indexing genome graphs

A \emph{text index} maps query strings to their occurrences in the indexed text.
The occurrences are typically reported as a list of starting positions, from which one can easily determine the substrings matching the query.

Indexing the sequences encoded in a graph is more involved.
The number of $k$~bp paths often grows exponentially in $k$, and the number of distinct $k$-mers encoded as path labels may also grow exponentially.
Indexing or even enumerating all $k$-mers in the graph may be infeasible for reasonable values of $k$, and if the starting position of the occurrence reported by the index is in a complex region of the graph, there may be an exponential number of $k$~bp paths to investigate.

In practice, indexes for genome graphs must make trade-offs not encountered in text indexes.
In order to limit the exponential growth, the index may only support relatively short query strings.
Some indexes (e.g.\ \cite{Siren_2014}) support longer queries by doing extensive preprocessing.
In other indexes (e.g.\ \cite{Thachuk_2013,Huang_2013,Maciuca_2016}), queries mapping to complex graph regions can be slow.
Instead of indexing the entire graph, the index may only contain $k$-mers from a simplified graph, or from specific paths of the graph.
While finding the path matching the query may be expensive in some cases, indexes typically save space by only reporting the starting position of the match.

\subsection{Indexing sequences using a graph}

The FM-index \cite{Ferragina_2005} is a text index, based on the Burrows--Wheeler transform (BWT) \cite{Burrows_1994}, that is frequently used with DNA sequences.
One variant of the FM-index, the RLCSA \cite{Maekinen_2010}, run-length encodes the BWT, allowing it to store and index a collection of similar sequences space-efficiently.
\citeauthor{Huang_2010}\ \cite{Huang_2010} observed that if we know a good global alignment of the sequences, we can use that information to make the index both smaller and faster.
\citeauthor{Na_2016}\ \cite{Na_2016,Na_2018} developed this approach further in their FM-index of alignment.
While the articles do not mention it, both \citeauthor{Huang_2010}\ and \citeauthor{Na_2016}\ use the graph induced by the alignment as a space-efficient representation of the sequences.

\subsection{Indexing acyclic graphs}

One class of graph indexing methods supports only acyclic graphs, often represented as directed acyclic graphs (DAGs).
This constraint can exist either because the acyclicity of the graph provides guarantees that simplify the problem, or because incedental features of the method's software implementation preclude use on cyclic graphs.
One common class of DAGs, here called \emph{VCF graphs}, represents each contig as a mostly linear run of graph nodes, branching to allow only for substitutions and possibly insertions and deletions.
\todo{``VCF graph'' is a placeholder; is there a better term for this shape?}

GenomeMapper \cite{Schneeberger_2009} was the first graph-based read aligner.
It builds a VCF graph from a reference sequence and a set of variants.
To index the graph, GenomeMapper uses a simple hash-based $k$-mer index, with $k \le 13$ to limit memory usage.

GCSA \cite{Siren_2014} was the first attempt to use the BWT with graphs.
It either takes a prebuilt DAG or generates one from a multiple alignment of sequences.
GCSA then applies a number of graph transformations that preserve the language, or set of end-to-end sequences, until the nodes can be unambiguously sorted by the labels of the paths starting from the node.
When the complexity of the graph is sufficiently low, these transformations are reasonably fast and do not increase the size of the graph significantly.
However, a phase transition happens at a certain threshold, and the transformed graph quickly becomes too large to handle above the threshold.

BWBBLE \cite{Huang_2013} is a BWT-based representation for VCF graphs.
Simple substitutions are encoded in the sequence using IUPAC codes, and the sequence is indexed using a normal FM-index.
Because each base can be encoded using 8 different characters, the search branches at every base to cover all possible characters which admit the base searched.
In practice, most branches quickly run out of results and can be pruned from the search.
Insertions and deletions produce separate sequences, with selected amount of context around the variant.
The length of this context is an effective upper bound for query length.

The vBWT \cite{Maciuca_2016} took another approach to using the BWT for indexing VCF graphs.
It encodes variants as \texttt{(ref|alt1|alt2|\dots)} in the sequence.
When the search encounters a variant, it must branch to handle each allele separately.
Both BWBBLE and vBWT trade faster index construction for slower queries.
However, a combination of IUPAC codes for substitutions, the vBWT approach for other variants, and a $k$-mer index for matching the first 5--10 bases, is faster than either of the originals \cite{Buechler_2019}.

\subsection{General graphs}

Some text indexes are based on Lempel--Ziv parsing or context-free grammars.
These indexes first find partial matches between the query string and the indexed phrases and then combine the partial matches into full matches using two-dimensional range queries.
In the hypertext index \cite{Thachuk_2013}, each node is a separate phrase.
Queries mapping to a single node or crossing a single edge can be matched efficiently, while finding mappings to complex graph regions can be slow.

\citeauthor{Bowe_2012}\ \cite{Bowe_2012} used techniques similar to GCSA for representing de~Bruijn graphs.
If the graph transformations used in GCSA construction are stopped after $i$ steps, the resulting graph is equivalent to an order-$2^{i}$ de~Bruijn graph.
This de~Bruijn graph can be used to approximate the original graph.
There are no false negatives, but matches longer than $2^{i}$ may be false positives.
By using this approach, GCSA2 \cite{Siren_2017} attempts to support fast queries in arbitrary graphs.

GCSA2 faces the same issues with complex graphs as GCSA.
In practice, most graphs must be simplified before they can be indexed.
Typical simplifications include removing high-degree nodes and complex regions from the graph and replacing them with the reference sequence.
If a collection of haplotypes is available, the removed regions can be replaced with new subgraphs that contain separate paths for each distinct local haplotype \cite{Siren_2019}.
This way, the index contains all $k$-mers from the haplotypes, while usually missing $k$-mers from their recombinations.

\subsection{Indexing graphs using sequences}

Instead of attempting to index the entire graph, it is often sufficient to index only selected paths in it.
CHOP \cite{Mokveld_2018} takes the paths corresponding to haplotypes and breaks them into smaller pieces.
The distinct pieces form an artificial linear reference, which can be used with any read aligner.
The process guarantees that any substring of the haplotypes of length $k$ is also a substring of one of the pieces.
As with BWBBLE, $k$ represents an effective upper bound for query length.

The ``Pan-genome [sic] Seed Index'' (PSI) \cite{Ghaffaari_2019} follows a similar approach with artificial paths.
Instead of using haplotypes, PSI uses a greedy algorithm to find a set of paths that covers as many $k$~bp windows in the graph as possible.
An index using these paths alone already works well in practice.

When a fully sensitive index is needed, PSI can reverse the role of the query strings and the graph.
While complex graph regions may contain an excessive number of $k$-mers, the reads mapping to them only contain a limited number of $k$-mers.
By indexing a batch of reads and searching for the complex regions in that index, all mappings of the query strings to the graph can be found with reasonable resources.


\subsection{Other population-ish succinct data structures}
% Erik

\subsubsection{de Bruijn}

% BOSS: \cite{Bowe_2012} (\cite{Roedland_2013} is similar)

\subsubsection{VCFs / genotype calls / haplotypes / binary matrices}

\subsubsection{gPBWT, GBWT}

% Jouni: We should at least include this


\subsubsection{Alignments / collections of strings}

% Jouni: We probably don't have space for this.



